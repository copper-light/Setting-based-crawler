2018-11-08 17:56:58 INFO  Crawler:224 - ============== Start Crawler =============
2018-11-08 17:56:58 INFO  Crawler:225 - CONFIG FILE    : ./config/config_domeggook.json
2018-11-08 17:56:58 INFO  Crawler:228 - CMD PARAM 00   : 김
2018-11-08 17:56:58 INFO  Crawler:231 - CRAWLER NAME   : domeggook
2018-11-08 17:56:58 INFO  Crawler:232 - CRAWLER TYPE   : SCENARIO_DYNAMIC
2018-11-08 17:56:58 INFO  Crawler:233 - CRAWLER DELAY  : 1 sec
2018-11-08 17:56:58 INFO  Crawler:234 - IGNORE ROBOTS  : true
2018-11-08 17:56:58 INFO  Crawler:235 - LIMIT_COUNT    : 3
2018-11-08 17:56:58 INFO  Crawler:236 - FILTER COUNT   : 0
2018-11-08 17:56:58 INFO  Crawler:240 - SCENARIO COUNT : 2
2018-11-08 17:56:58 INFO  Crawler:241 - COLLECT COUNT  : 1
2018-11-08 17:56:58 INFO  Crawler:242 - SAVE TYPE      : DB
2018-11-08 17:56:58 INFO  Crawler:243 - SAVE HTML      : true
2018-11-08 17:56:58 INFO  Crawler:244 - ==========================================
2018-11-08 17:57:09 INFO  Crawler:274 - [Progress 1] save : 0, err : 0, remain_work : 2, total : 3
2018-11-08 17:57:10 INFO  Crawler:274 - [Progress 2] save : 0, err : 0, remain_work : 53, total : 55
2018-11-08 17:57:12 INFO  Crawler:274 - [Progress 3] save : 0, err : 0, remain_work : 55, total : 58
2018-11-08 17:57:13 INFO  Crawler:274 - [Progress 4] save : 0, err : 0, remain_work : 54, total : 58
2018-11-08 17:57:16 ERROR Crawler:266 - [ERR URL] http://domeggook.com/8031622?sfc=ttl&sf=ttl&sw=%B1%E8
2018-11-08 17:57:16 ERROR Crawler:269 - L ERR_WRITE : Contents write failed : Duplicate entry '8031622' for key 'PRIMARY'
2018-11-08 17:57:16 INFO  Crawler:274 - [Progress 5] save : 0, err : 1, remain_work : 53, total : 58
2018-11-08 17:57:17 INFO  Crawler:274 - [Progress 6] save : 0, err : 1, remain_work : 52, total : 58
2018-11-08 17:57:18 INFO  Crawler:274 - [Progress 7] save : 0, err : 1, remain_work : 54, total : 61
2018-11-08 17:57:19 INFO  Crawler:274 - [Progress 8] save : 0, err : 1, remain_work : 53, total : 61
2018-11-08 17:57:22 ERROR Crawler:266 - [ERR URL] http://domeggook.com/7515374?sfc=ttl&sf=ttl&sw=%B1%E8
2018-11-08 17:57:22 ERROR Crawler:269 - L ERR_WRITE : Contents write failed : Duplicate entry '7515374' for key 'PRIMARY'
2018-11-08 17:57:22 INFO  Crawler:274 - [Progress 9] save : 0, err : 2, remain_work : 52, total : 61
2018-11-08 17:57:23 INFO  Crawler:274 - [Progress 10] save : 0, err : 2, remain_work : 51, total : 61
2018-11-08 17:57:24 INFO  Crawler:274 - [Progress 11] save : 0, err : 2, remain_work : 53, total : 64
2018-11-08 17:57:25 INFO  Crawler:274 - [Progress 12] save : 0, err : 2, remain_work : 52, total : 64
2018-11-08 17:57:27 ERROR Crawler:266 - [ERR URL] http://domeggook.com/8269048?sfc=ttl&sf=ttl&sw=%B1%E8
2018-11-08 17:57:27 ERROR Crawler:269 - L ERR_WRITE : Contents write failed : Duplicate entry '8269048' for key 'PRIMARY'
2018-11-08 17:57:27 INFO  Crawler:274 - [Progress 13] save : 0, err : 3, remain_work : 51, total : 64
2018-11-08 17:57:28 INFO  Crawler:308 - ============== Finish Crawler =============
2018-11-08 17:57:28 INFO  Crawler:309 - [total time] 00:00:29
2018-11-08 17:57:28 INFO  Crawler:310 - [save contents] 0
2018-11-08 17:57:28 INFO  Crawler:311 - [error work] 3
2018-11-08 17:57:28 INFO  Crawler:312 - [remain work] 0
2018-11-08 17:57:28 INFO  Crawler:313 - [total processed work] 13
2018-11-08 17:57:28 INFO  Crawler:224 - ============== Start Crawler =============
2018-11-08 17:57:28 INFO  Crawler:225 - CONFIG FILE    : ./config/config_domeggook.json
2018-11-08 17:57:28 INFO  Crawler:228 - CMD PARAM 00   : 라면
2018-11-08 17:57:28 INFO  Crawler:231 - CRAWLER NAME   : domeggook
2018-11-08 17:57:28 INFO  Crawler:232 - CRAWLER TYPE   : SCENARIO_DYNAMIC
2018-11-08 17:57:28 INFO  Crawler:233 - CRAWLER DELAY  : 1 sec
2018-11-08 17:57:28 INFO  Crawler:234 - IGNORE ROBOTS  : true
2018-11-08 17:57:28 INFO  Crawler:235 - LIMIT_COUNT    : 3
2018-11-08 17:57:28 INFO  Crawler:236 - FILTER COUNT   : 0
2018-11-08 17:57:28 INFO  Crawler:240 - SCENARIO COUNT : 2
2018-11-08 17:57:28 INFO  Crawler:241 - COLLECT COUNT  : 1
2018-11-08 17:57:28 INFO  Crawler:242 - SAVE TYPE      : DB
2018-11-08 17:57:28 INFO  Crawler:243 - SAVE HTML      : true
2018-11-08 17:57:28 INFO  Crawler:244 - ==========================================
2018-11-08 17:57:28 ERROR Crawler:252 - Session ID is null. Using WebDriver after calling quit()?
Build info: version: '3.11.0', revision: 'e59cfb3', time: '2018-03-11T20:26:55.152Z'
System info: host: 'LAPTOP-94HKRVCK', ip: '192.168.56.1', os.name: 'Windows 10', os.arch: 'amd64', os.version: '10.0', java.version: '1.8.0_161'
Driver info: driver.version: RemoteWebDriver
org.openqa.selenium.NoSuchSessionException: Session ID is null. Using WebDriver after calling quit()?
Build info: version: '3.11.0', revision: 'e59cfb3', time: '2018-03-11T20:26:55.152Z'
System info: host: 'LAPTOP-94HKRVCK', ip: '192.168.56.1', os.name: 'Windows 10', os.arch: 'amd64', os.version: '10.0', java.version: '1.8.0_161'
Driver info: driver.version: RemoteWebDriver
	at org.openqa.selenium.remote.HttpCommandExecutor.execute(HttpCommandExecutor.java:125)
	at org.openqa.selenium.remote.service.DriverCommandExecutor.execute(DriverCommandExecutor.java:83)
	at org.openqa.selenium.remote.RemoteWebDriver.execute(RemoteWebDriver.java:545)
	at org.openqa.selenium.remote.RemoteWebDriver$RemoteWebDriverOptions$RemoteWindow.setSize(RemoteWebDriver.java:801)
	at com.onycom.crawler.scraper.SeleniumScraper.connectSelenium(SeleniumScraper.java:363)
	at com.onycom.crawler.scraper.SeleniumScraper.open(SeleniumScraper.java:51)
	at com.onycom.SettingBasedCrawler.Crawler$1.start(Crawler.java:248)
	at com.onycom.crawler.core.WorkManager.start(WorkManager.java:83)
	at com.onycom.SettingBasedCrawler.Crawler.start(Crawler.java:209)
	at com.onycom.SettingBasedCrawler.App.main(App.java:56)
2018-11-08 17:57:28 INFO  Crawler:256 - ============== Terminate Crawler =============
2018-11-08 17:57:28 ERROR Crawler:257 - Can't start Crawler. Initialization failed.
